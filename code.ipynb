{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        INTENSITY TRANSFORMATION AND SPATIAL FILTERING APPLIED   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "# Show original image\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "img = cv2.imread('picture3.jpg', 0)\n",
    "# Show original image\n",
    "cv2.imshow('Original Gray Scale Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output\n",
    "cv2.imwrite('grayscale_image.jpg', img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        SECTION 1 ) INTENSITY TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        1) IMAGE NEGATIVES      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Show original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate maximum intensity level\n",
    "L = 255\n",
    "\n",
    "# Perform image negation\n",
    "negated_img = L - img\n",
    "\n",
    "# Show negated image\n",
    "cv2.imshow('Negated Image', negated_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output\n",
    "cv2.imwrite('negated_image.jpg', negated_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2) LOG TRANSFORMATIONS      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15300\\1207110890.py:11: RuntimeWarning: divide by zero encountered in log\n",
      "  log_transformed = c * np.log(1 + img)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_15300\\1207110890.py:14: RuntimeWarning: invalid value encountered in cast\n",
      "  log_transformed = np.array(log_transformed, dtype = np.uint8)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image. \n",
    "img = cv2.imread('picture3.jpg') \n",
    "\n",
    "# Show original image.\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Apply log transform. \n",
    "c = 255/(np.log(1 + np.max(img))) \n",
    "log_transformed = c * np.log(1 + img) \n",
    "\n",
    "# Specify the data type. \n",
    "log_transformed = np.array(log_transformed, dtype = np.uint8) \n",
    "\n",
    "# Show transformed image.\n",
    "cv2.imshow('Log Transformed Image', log_transformed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output. \n",
    "cv2.imwrite('log_transformed.jpg', log_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3) INVERSE LOG FUNCTION     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image. \n",
    "img = cv2.imread('picture3.jpg') \n",
    "\n",
    "# Show original image.\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Read the log-transformed image\n",
    "log_transformed_img = cv2.imread('log_transformed.jpg')\n",
    "\n",
    "# Apply inverse log transformation\n",
    "inverse_log_transformed = np.exp(log_transformed_img / c) - 1\n",
    "\n",
    "# Specify the data type\n",
    "inverse_log_transformed = np.array(inverse_log_transformed, dtype=np.uint8)\n",
    "\n",
    "# Show the inverse log-transformed image\n",
    "cv2.imshow('Inverse Log Transformed Image', inverse_log_transformed)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output\n",
    "cv2.imwrite('inverse_log_transformed.jpg', inverse_log_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4) POWER LAW (Gamma Transformations)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the image. \n",
    "img = cv2.imread('picture3.jpg') \n",
    "\n",
    "# Show original image.\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Trying 4 gamma values. \n",
    "for gamma in [0.1, 0.5, 1.2, 2.2]: \n",
    "    \n",
    "    # Apply gamma correction. \n",
    "    gamma_corrected = np.array(255*(img / 255) ** gamma, dtype='uint8') \n",
    "    \n",
    "    # Show transformed image.\n",
    "    cv2.imshow('Gamma Transformed Image (Gamma = ' + str(gamma) + ')', gamma_corrected)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # Save edited images.\n",
    "    filename = 'gamma_transformed_gamma_' + str(gamma) + '.jpg'\n",
    "    cv2.imwrite(filename, gamma_corrected)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5) CONTRAST STRETCHING      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the gray scale image. \n",
    "img = cv2.imread('picture3.jpg',0) \n",
    "\n",
    "# Show original image.\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Function to map each intensity level to output intensity level. \n",
    "def pixelVal(pix, r1, s1, r2, s2): \n",
    "\tif (0 <= pix and pix <= r1): \n",
    "\t\treturn (s1 / r1)*pix \n",
    "\telif (r1 < pix and pix <= r2): \n",
    "\t\treturn ((s2 - s1)/(r2 - r1)) * (pix - r1) + s1 \n",
    "\telse: \n",
    "\t\treturn ((255 - s2)/(255 - r2)) * (pix - r2) + s2 \n",
    "\n",
    "# Define parameters. \n",
    "r1 = 70\n",
    "s1 = 0\n",
    "r2 = 100\n",
    "s2 = 200\n",
    "\n",
    "# Vectorize the function to apply it to each value in the Numpy array. \n",
    "pixelVal_vec = np.vectorize(pixelVal) \n",
    "\n",
    "# Apply contrast stretching. \n",
    "contrast_stretched = pixelVal_vec(img, r1, s1, r2, s2) \n",
    "\n",
    "# Show transformed image.\n",
    "cv2.imshow('Contrast stetched', contrast_stretched)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save edited image. \n",
    "cv2.imwrite('contrast_stretch.jpg', contrast_stretched) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*applying thresholding function*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply thresholding.\n",
    "thresh_value = 150  # Example threshold value\n",
    "_, thresholded_img = cv2.threshold(contrast_stretched, thresh_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Show thresholded image.\n",
    "cv2.imshow('Thresholded Image', thresholded_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save edited image.\n",
    "cv2.imwrite('contrast_stretch_with_threshold.jpg', thresholded_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        6) INTENSITY LEVEL SLICING         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*it is applied on grayscale images* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image. \n",
    "img = cv2.imread('picture3.jpg') \n",
    "\n",
    "# Show original image\n",
    "cv2.imshow('Original image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform intensity level slicing\n",
    "def intensity_level_slicing(img, lower_thresh, upper_thresh, enhance_val):\n",
    "    # Copy the input image to preserve the original\n",
    "    output_img = np.copy(img)\n",
    "    \n",
    "    # Iterate over each pixel and apply intensity level slicing\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if lower_thresh <= img[i, j] <= upper_thresh:\n",
    "                output_img[i, j] = enhance_val\n",
    "                \n",
    "    return output_img\n",
    "\n",
    "# Open the gray scale image\n",
    "img_g = cv2.imread('picture3.jpg',0)\n",
    "\n",
    "# Show gray scale image\n",
    "cv2.imshow('Gray scale image', img_g)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Define parameters for intensity level slicing\n",
    "lower_threshold = 100\n",
    "upper_threshold = 200\n",
    "enhance_value = 255\n",
    "\n",
    "# Apply intensity level slicing\n",
    "sliced_img = intensity_level_slicing(img_g, lower_threshold, upper_threshold, enhance_value)\n",
    "\n",
    "# Show the sliced image\n",
    "cv2.imshow('Intensity Level Slicing', sliced_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the output image\n",
    "cv2.imwrite('intensity_level_sliced.jpg', sliced_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        7) BIT PLANE SLICING         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*is applied on grayscale images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to perform bit-plane slicing\n",
    "def bit_plane_slicing(img, plane):\n",
    "    # Extract the specified bit plane\n",
    "    plane_img = (img >> plane) & 1\n",
    "    # Scale the pixel values to 0-255\n",
    "    plane_img *= 255\n",
    "    return plane_img.astype(np.uint8)\n",
    "\n",
    "# Open the image\n",
    "img = cv2.imread('picture3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Show original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Define the number of bit planes\n",
    "num_planes = 8\n",
    "\n",
    "# Decompose the image into bit planes and display each decomposition\n",
    "bit_plane_images = []\n",
    "for i in range(num_planes):\n",
    "    plane_img = bit_plane_slicing(img, i)\n",
    "    bit_plane_images.append(plane_img)\n",
    "    cv2.imshow('Bit Plane ' + str(i), plane_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "     # Save the bit plane image\n",
    "    cv2.imwrite('bit_plane_' + str(i) + '.jpg', plane_img)\n",
    "\n",
    "\n",
    "# Reconstruct the image\n",
    "reconstructed_img = np.zeros_like(img)\n",
    "for i in range(num_planes):\n",
    "    reconstructed_img += bit_plane_images[i] * (2 ** i)\n",
    "\n",
    "# Show the reconstructed image\n",
    "cv2.imshow('Reconstructed Image', reconstructed_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the reconstructed image\n",
    "cv2.imwrite('reconstructed_image.jpg', reconstructed_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        8) HISTOGRAM EQUALIZATION      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*On grayscale* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image. \n",
    "img = cv2.imread('picture3.jpg') \n",
    "\n",
    "# Show original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Open the gray scale image\n",
    "img_g = cv2.imread('picture3.jpg', 0)\n",
    "\n",
    "# Show gray scale image\n",
    "cv2.imshow('Gray scale image', img_g)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Create a CLAHE object (Arguments are optional)\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Apply CLAHE to the image\n",
    "equalized_img = clahe.apply(img_g)\n",
    "\n",
    "cv2.imshow('Equalized Image', equalized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the equalized image\n",
    "cv2.imwrite('local_histogram_equalized_grayscale.jpg', equalized_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on RGB color space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Show original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Convert the image to LAB color space\n",
    "lab_img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# Split the LAB image into its channels\n",
    "l, a, b = cv2.split(lab_img)\n",
    "\n",
    "# Create a CLAHE object \n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "\n",
    "# Apply CLAHE to the L channel\n",
    "l_equalized = clahe.apply(l)\n",
    "\n",
    "# Merge the equalized L channel with the original A and B channels\n",
    "lab_equalized = cv2.merge((l_equalized, a, b))\n",
    "\n",
    "# Convert the equalized LAB image back to BGR color space\n",
    "equalized_img = cv2.cvtColor(lab_equalized, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# Show the equalized image\n",
    "cv2.imshow('Equalized Image', equalized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Save the equalized image\n",
    "cv2.imwrite('local_histogram_equalized_rgb.jpg', equalized_img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        SECTION 2 ) SPATIAL FILTERING "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        A) LOW PASS FILTERING   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        1) BOX FILTER   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on rgb color space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image in color (BGR) mode\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Obtain number of rows and columns of the image\n",
    "m, n, _ = img.shape  # Get the third value from the shape tuple for the number of channels (3 for color images)\n",
    "\n",
    "# Develop Box filter (5x5) kernel\n",
    "kernel = np.ones((5, 5), dtype=np.float32) / 25\n",
    "\n",
    "# Split the image into its color channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Convolve the kernel over each color channel independently\n",
    "b_filtered = cv2.filter2D(b, -1, kernel)\n",
    "g_filtered = cv2.filter2D(g, -1, kernel)\n",
    "r_filtered = cv2.filter2D(r, -1, kernel)\n",
    "\n",
    "# Merge the filtered color channels back into the RGB image\n",
    "img_new = cv2.merge((b_filtered, g_filtered, r_filtered))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_box_filter_rgb.jpg', img_new)\n",
    "\n",
    "# Display blurred image using box filter\n",
    "cv2.imshow('Blurred Image (Box Filter RGB)', img_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on gray scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image in grayscale mode\n",
    "img_gray = cv2.imread('picture3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display original grayscale image\n",
    "cv2.imshow('Original Grayscale Image', img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Develop Box filter (5x5) kernel\n",
    "kernel = np.ones((5, 5), dtype=np.float32) / 25\n",
    "\n",
    "# Convolve the kernel over the grayscale image\n",
    "img_filtered = cv2.filter2D(img_gray, -1, kernel)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_box_filter_grayscale.jpg', img_filtered)\n",
    "\n",
    "# Display blurred grayscale image using box filter\n",
    "cv2.imshow('Blurred Image (Box Filter Grayscale)', img_filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2) GAUSIAN BLUR "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on RGB color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Obtain number of rows and columns of the image\n",
    "m, n, _ = img.shape  # Get the third value from the shape tuple for the number of channels (3 for color images)\n",
    "\n",
    "# Define Gaussian kernel size and standard deviation\n",
    "ksize = (5, 5)  # Kernel size\n",
    "sigma = 1.5     # Standard deviation\n",
    "\n",
    "# Create Gaussian kernel\n",
    "kernel_x = cv2.getGaussianKernel(ksize[0], sigma)\n",
    "kernel_y = cv2.getGaussianKernel(ksize[1], sigma)\n",
    "kernel = np.multiply(kernel_x, np.transpose(kernel_y))\n",
    "\n",
    "# Split the image into its color channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Perform 2D convolution with Gaussian kernel on each color channel\n",
    "b_filtered = cv2.filter2D(b, -1, kernel)\n",
    "g_filtered = cv2.filter2D(g, -1, kernel)\n",
    "r_filtered = cv2.filter2D(r, -1, kernel)\n",
    "\n",
    "# Merge the filtered color channels back into the RGB image\n",
    "img_new = cv2.merge((b_filtered, g_filtered, r_filtered))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_gaussian_filter_rgb.jpg', img_new)\n",
    "\n",
    "# Display blurred image using Gaussian filter\n",
    "cv2.imshow('Blurred Image (Gaussian Filter RGB)', img_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on gray scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image in grayscale mode\n",
    "img_gray = cv2.imread('picture3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display original grayscale image\n",
    "cv2.imshow('Original Grayscale Image', img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Define Gaussian kernel size and standard deviation\n",
    "ksize = (5, 5)  # Kernel size\n",
    "sigma = 1.5     # Standard deviation\n",
    "\n",
    "# Create Gaussian kernel\n",
    "kernel_x = cv2.getGaussianKernel(ksize[0], sigma)\n",
    "kernel_y = cv2.getGaussianKernel(ksize[1], sigma)\n",
    "kernel = np.multiply(kernel_x, np.transpose(kernel_y))\n",
    "\n",
    "# Perform 2D convolution with Gaussian kernel on the grayscale image\n",
    "img_filtered = cv2.filter2D(img_gray, -1, kernel)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_gaussian_filter_grayscale.jpg', img_filtered)\n",
    "\n",
    "# Display blurred grayscale image using Gaussian filter\n",
    "cv2.imshow('Blurred Image (Gaussian Filter Grayscale)', img_filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3) MEDIAN FILTER     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on rgb color space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image into its color channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Apply median filter to each color channel independently\n",
    "b_filtered = cv2.medianBlur(b, 5)  # Kernel size set to 5x5, can be adjusted as needed\n",
    "g_filtered = cv2.medianBlur(g, 5)\n",
    "r_filtered = cv2.medianBlur(r, 5)\n",
    "\n",
    "# Merge the filtered color channels back into the RGB image\n",
    "img_new = cv2.merge((b_filtered, g_filtered, r_filtered))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_median_filter_rgb.jpg', img_new)\n",
    "\n",
    "# Display blurred image using median filter\n",
    "cv2.imshow('Blurred Image (Median Filter RGB)', img_new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image in grayscale mode\n",
    "img_gray = cv2.imread('picture3.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Display original grayscale image\n",
    "cv2.imshow('Original Grayscale Image', img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Apply median filter to the grayscale image\n",
    "img_filtered = cv2.medianBlur(img_gray, 5)  # Kernel size set to 5x5, can be adjusted as needed\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('blurred_median_filter_grayscale.jpg', img_filtered)\n",
    "\n",
    "# Display blurred grayscale image using median filter\n",
    "cv2.imshow('Blurred Image (Median Filter Grayscale)', img_filtered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        B) HIGH PASS FILTERING     \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        1) FIRST DERIVATIVE     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image into its color channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Sobel kernel for horizontal edge detection\n",
    "sobel_kernel_x = np.array([[-1, 0, 1],\n",
    "                           [-2, 0, 2],\n",
    "                           [-1, 0, 1]])\n",
    "\n",
    "# Sobel kernel for vertical edge detection\n",
    "sobel_kernel_y = np.array([[-1, -2, -1],\n",
    "                           [ 0,  0,  0],\n",
    "                           [ 1,  2,  1]])\n",
    "\n",
    "# Apply Sobel kernels for horizontal and vertical edge detection to each color channel\n",
    "gradient_x_b = cv2.filter2D(b, -1, sobel_kernel_x)\n",
    "gradient_y_b = cv2.filter2D(b, -1, sobel_kernel_y)\n",
    "\n",
    "gradient_x_g = cv2.filter2D(g, -1, sobel_kernel_x)\n",
    "gradient_y_g = cv2.filter2D(g, -1, sobel_kernel_y)\n",
    "\n",
    "gradient_x_r = cv2.filter2D(r, -1, sobel_kernel_x)\n",
    "gradient_y_r = cv2.filter2D(r, -1, sobel_kernel_y)\n",
    "\n",
    "# Combine horizontal and vertical gradients for each color channel\n",
    "gradient_b = cv2.addWeighted(cv2.convertScaleAbs(gradient_x_b), 0.5,\n",
    "                              cv2.convertScaleAbs(gradient_y_b), 0.5, 0)\n",
    "\n",
    "gradient_g = cv2.addWeighted(cv2.convertScaleAbs(gradient_x_g), 0.5,\n",
    "                              cv2.convertScaleAbs(gradient_y_g), 0.5, 0)\n",
    "\n",
    "gradient_r = cv2.addWeighted(cv2.convertScaleAbs(gradient_x_r), 0.5,\n",
    "                              cv2.convertScaleAbs(gradient_y_r), 0.5, 0)\n",
    "\n",
    "# Merge the gradients of each color channel back into the image\n",
    "gradient = cv2.merge((gradient_b, gradient_g, gradient_r))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('first_order_derivative_high_pass_rgb.jpg', gradient)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('First Order Derivative High Pass Filtering (RGB)', gradient)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        2) SECOND DERIVATIVE     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image into its color channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Define Laplacian kernel\n",
    "laplacian_kernel = np.array([[0, 1, 0],\n",
    "                             [1, -4, 1],\n",
    "                             [0, 1, 0]])\n",
    "\n",
    "# Apply Laplacian kernel to each color channel\n",
    "laplacian_b = cv2.filter2D(b, -1, laplacian_kernel)\n",
    "laplacian_g = cv2.filter2D(g, -1, laplacian_kernel)\n",
    "laplacian_r = cv2.filter2D(r, -1, laplacian_kernel)\n",
    "\n",
    "# Merge the Laplacian-filtered color channels back into the image\n",
    "laplacian_img = cv2.merge((laplacian_b, laplacian_g, laplacian_r))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('second_order_derivative_high_pass_rgb.jpg', laplacian_img)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('Second Order Derivative High Pass Filtering (RGB)', laplacian_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        3) ROBERTS FILTER       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Used on gray scale images for meaningful results*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg', 0)\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Gray scale Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Roberts kernels for edge detection\n",
    "roberts_kernel_x = np.array([[1, 0],\n",
    "                             [0, -1]])\n",
    "\n",
    "roberts_kernel_y = np.array([[0, 1],\n",
    "                             [-1, 0]])\n",
    "\n",
    "# Apply Roberts kernels for edge detection\n",
    "roberts_x = cv2.filter2D(img, -1, roberts_kernel_x)\n",
    "roberts_y = cv2.filter2D(img, -1, roberts_kernel_y)\n",
    "\n",
    "# Combine the Roberts edge detections\n",
    "roberts = cv2.addWeighted(cv2.convertScaleAbs(roberts_x), 0.5,\n",
    "                           cv2.convertScaleAbs(roberts_y), 0.5, 0)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('roberts_edge_detection.jpg', roberts)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('Roberts Edge Detection', roberts)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        4) UNSHARP MASKING      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on RGB color space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image into its RGB channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Apply Gaussian blur to each color channel separately\n",
    "blurred_b = cv2.GaussianBlur(b, (5, 5), 0)\n",
    "blurred_g = cv2.GaussianBlur(g, (5, 5), 0)\n",
    "blurred_r = cv2.GaussianBlur(r, (5, 5), 0)\n",
    "\n",
    "# Calculate the unsharp mask for each channel\n",
    "unsharp_mask_b = cv2.addWeighted(b, 2, blurred_b, -1, 0)\n",
    "unsharp_mask_g = cv2.addWeighted(g, 2, blurred_g, -1, 0)\n",
    "unsharp_mask_r = cv2.addWeighted(r, 2, blurred_r, -1, 0)\n",
    "\n",
    "# Merge the RGB channels back into the image\n",
    "unsharp_mask = cv2.merge((unsharp_mask_b, unsharp_mask_g, unsharp_mask_r))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('unsharp_masking_colored_rgb.jpg', unsharp_mask)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('Unsharp Masking (Colored)', unsharp_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on gray scale*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg', 0)\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Gray scale Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Apply Gaussian blur to the original image\n",
    "blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "# Calculate the unsharp mask\n",
    "unsharp_mask = cv2.addWeighted(img, 2, blurred, -1, 0)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('unsharp_masking_grayscale.jpg', unsharp_mask)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('Unsharp Masking', unsharp_mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        5) HIGH BOOST FILTERING         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on RGB color space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg')\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Split the image into its RGB channels\n",
    "b, g, r = cv2.split(img)\n",
    "\n",
    "# Define the kernel for high-boost filtering\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1,  9, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Apply the kernel for high-boost filtering to each color channel\n",
    "b_high_boost = cv2.filter2D(b, -1, kernel)\n",
    "g_high_boost = cv2.filter2D(g, -1, kernel)\n",
    "r_high_boost = cv2.filter2D(r, -1, kernel)\n",
    "\n",
    "# Merge the high-boost filtered color channels back into the RGB image\n",
    "high_boost_img = cv2.merge((b_high_boost, g_high_boost, r_high_boost))\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('high_boost_filtering_rgb.jpg', high_boost_img)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('High-Boost Filtering (RGB)', high_boost_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*on gray scale*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread('picture3.jpg', 0)\n",
    "\n",
    "# Display original image\n",
    "cv2.imshow('Gray scale Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Define the kernel for high-boost filtering\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1,  9, -1],\n",
    "                   [-1, -1, -1]])\n",
    "\n",
    "# Apply the kernel for high-boost filtering\n",
    "high_boost = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "# Save the resulting image\n",
    "cv2.imwrite('high_boost_filtering_grayscale.jpg', high_boost)\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('High-Boost Filtering', high_boost)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
